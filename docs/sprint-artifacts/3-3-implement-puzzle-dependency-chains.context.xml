<story-context id=".bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>3</epicId>
    <storyId>3</storyId>
    <title>Implement Puzzle Dependency Chains</title>
    <status>drafted</status>
    <generatedAt>2025-12-04</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/sprint-artifacts/3-3-implement-puzzle-dependency-chains.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>game designer</asA>
    <iWant>to ensure AI-generated puzzles are always solvable and logically connected</iWant>
    <soThat>players never encounter unsolvable scenarios</soThat>
    <tasks>
- [ ] AC 1: Extend `services/ai_service.py` for puzzle dependency logic.
  - [ ] Subtask: Implement functions to formulate prompts that instruct the Gemini API to generate puzzles with explicit prerequisites and outcomes.
  - [ ] Subtask: Consider graph-based representations of puzzle dependencies within prompts.
- [ ] AC 1, 2: Implement internal logic for verifying puzzle solvability.
  - [ ] Subtask: Develop functions in `services/game_logic.py` to analyze a generated puzzle sequence and confirm its solvability.
  - [ ] Subtask: This might involve simulating puzzle progression or checking for circular dependencies.
- [ ] AC 2: Integrate puzzle verification with game state.
  - [ ] Subtask: Update `GameSession.puzzle_state` to store metadata about puzzle dependencies and solvability status.
- [ ] AC 1, 2: Implement unit and integration tests.
  - [ ] Subtask: Write unit tests for puzzle dependency logic in `services/ai_service.py`, mocking the Gemini API to verify correct prompt construction.
  - [ ] Subtask: Write unit tests for the puzzle solvability verification functions in `services/game_logic.py`.
  - [ ] Subtask: Integration tests for API endpoints that trigger puzzle generation, ensuring that only solvable sequences are created.
</tasks>
  </story>

  <acceptanceCriteria>
    <criterion>Given a set of dynamically generated puzzles for an escape room, when the AI generates the puzzle sequence, then the puzzles are arranged in a solvable dependency chain (e.g., key for door A is found by solving puzzle B).</criterion>
    <criterion>And the game verifies the solvability of the generated chain.</criterion>
</acceptanceCriteria>

  <artifacts>
<docs>
    <doc>
        <path>docs/prd.md</path>
        <title>Product Requirements Document: AI Escape</title>
        <section>FR-005: Detailed specifications for puzzle types</section>
        <snippet>Detailed specifications for puzzle types (Observation, Riddle, etc.) and the AI's adaptation logic will be developed.</snippet>
    </doc>
    <doc>
        <path>docs/architecture.md</path>
        <title>Architecture</title>
        <section>AI Service Integration</section>
        <snippet>Utilizes Gemini Pro / Gemini 1.5 Pro.</snippet>
    </doc>
    <doc>
        <path>docs/architecture.md</path>
        <title>Architecture</title>
        <section>AI Client Library</section>
        <snippet>Employs `google-generativeai 0.8.5` for interacting with the Gemini API.</snippet>
    </doc>
    <doc>
        <path>docs/architecture.md</path>
        <title>Architecture</title>
        <section>Prompt Management Strategy</section>
        <snippet>Structured Prompting with "Puzzle Dependency Chains".</snippet>
    </doc>
    <doc>
        <path>docs/architecture.md</path>
        <title>Architecture</title>
        <section>Data Architecture</section>
        <snippet>`GameSession.puzzleState` will be crucial for providing context to the AI for dynamic adaptation.</snippet>
    </doc>
    <doc>
        <path>docs/epics.md</path>
        <title>ibe160 - Epic Breakdown</title>
        <section>Epic 3: The AI Puzzle Master</section>
        <snippet>This Epic focuses on empowering the AI to dynamically generate and adapt puzzles within the "AI Escape" game, building upon the coherent narrative framework established in Epic 2.</snippet>
    </doc>
    <doc>
        <path>docs/epics.md</path>
        <title>ibe160 - Epic Breakdown</title>
        <section>Story 3.3: Implement Puzzle Dependency Chains</section>
        <snippet>Story 3.3 focuses on ensuring AI-generated puzzles are always solvable and logically connected, preventing unsolvable scenarios through internal AI logic.</snippet>
    </doc>
    <doc>
        <path>docs/ux-design-specification.md</path>
        <title>AI Escape - UX Design Specification</title>
        <section>5. User Journey Flows</section>
        <snippet>UX Design outlines user journey flows for New Game Creation and Load Game, which will rely on the backend's game state management to function correctly. This implies the need for dynamic content in the UI.</snippet>
    </doc>
</docs>
    <code>
        <code-ref>
            <path>services/ai_service.py</path>
            <kind>file</kind>
            <reason>Extend for puzzle dependency logic (formulate prompts with prerequisites and outcomes)</reason>
        </code-ref>
        <code-ref>
            <path>services/game_logic.py</path>
            <kind>file</kind>
            <reason>Implement internal logic for verifying puzzle solvability</reason>
        </code-ref>
        <code-ref>
            <path>models.py</path>
            <kind>file</kind>
            <reason>Update `GameSession.puzzle_state` to store metadata about puzzle dependencies and solvability status</reason>
        </code-ref>
        <code-ref>
            <path>tests/</path>
            <kind>directory</kind>
            <reason>For new unit and integration tests</reason>
        </code-ref>
    </code>
    <dependencies>
      <python>
        <package name="Flask" version="3.1.2" />
        <package name="python-dotenv" version="?" />
        <package name="gunicorn" version="?" />
        <package name="pytest" version="?" />
        <package name="google-generativeai" version="0.8.5" />
        <note>Core Python dependencies for the Flask application and Google Gemini API client.</note>
      </python>
      <node>
        <package name="playwright" version="?" />
        <note>Existing Node.js project dependencies for E2E testing.</note>
      </node>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint>
        <type>Required Pattern</type>
        <description>Python Flask application structure (modular, with `app.py`, `static/`, `templates/`, `models.py`, `routes.py`, `services/`, `tests/`).</description>
        <source>docs/architecture.md#Project-Structure</source>
    </constraint>
    <constraint>
        <type>Required Pattern</type>
        <description>WCAG 2.1 Level AA accessibility compliance.</description>
        <source>docs/architecture.md#Accessibility-Implementation</source>
    </constraint>
    <constraint>
        <type>Required Pattern</type>
        <description>Stateless JWT Authentication.</description>
        <source>docs/architecture.md#Security-Architecture</source>
    </constraint>
    <constraint>
        <type>Layer Restriction</type>
        <description>Frontend (Jinja2 templates/Static assets) &lt;-> Backend (Flask Routes/API Endpoints).</description>
        <source>docs/architecture.md#Integration-Points</source>
    </constraint>
    <constraint>
        <type>Layer Restriction</type>
        <description>Flask Routes/API Endpoints &lt;-> AI Service (Gemini API).</description>
        <source>docs/architecture.md#Integration-Points</source>
    </constraint>
    <constraint>
        <type>Layer Restriction</type>
        <description>Flask Routes/API Endpoints &lt;-> Database (Supabase PostgreSQL via SQLAlchemy).</description>
        <source>docs/architecture.md#Integration-Points</source>
    </constraint>
    <constraint>
        <type>Testing Requirement</type>
        <description>Unit Tests (Pytest with `pytest-mock`).</description>
        <source>docs/architecture.md#Comprehensive-Testing-Strategy</source>
    </constraint>
    <constraint>
        <type>Testing Requirement</type>
        <description>Integration Tests (Pytest).</description>
        <source>docs/architecture.md#Comprehensive-Testing-Strategy</source>
    </constraint>
    <constraint>
        <type>Testing Requirement</type>
        <description>E2E Tests (Playwright).</description>
        <source>docs/architecture.md#Comprehensive-Testing-Strategy</source>
    </constraint>
    <constraint>
        <type>Coding Standard</type>
        <description>Python Classes: `PascalCase`, Python Functions/Variables: `snake_case`, Python Modules/Files: `snake_case`, Database Tables: `snake_case` (plural), Database Columns: `snake_case`, API Endpoints: `kebab-case` for URL paths, `snake_case` for query parameters, Constants: `SCREAMING_SNAKE_CASE`.</description>
        <source>docs/architecture.md#Consistency-Rules</source>
    </constraint>
    <constraint>
        <type>Coding Standard</type>
        <description>Code Organization: Modular Flask application layout.</description>
        <source>docs/architecture.md#Code-Organization</source>
    </constraint>
</constraints>

<interfaces>
    <interface>
        <name>/generate_puzzle</name>
        <kind>REST endpoint</kind>
        <signature>POST /generate_puzzle</signature>
        <path>routes.py</path>
    </interface>
    <interface>
        <name>/evaluate_puzzle_solution</name>
        <kind>REST endpoint</kind>
        <signature>POST /evaluate_puzzle_solution</signature>
        <path>routes.py</path>
    </interface>
    <interface>
        <name>/adapt_puzzle</name>
        <kind>REST endpoint</kind>
        <signature>POST /adapt_puzzle</signature>
        <path>routes.py</path>
    </interface>
</interfaces>
  <tests>
    <standards>
      <standard>
        <framework>Pytest</framework>
        <type>Unit, Integration</type>
        <note>Unit tests should mock the Gemini API.</note>
        <source>docs/architecture.md#Testing-Strategy</source>
      </standard>
      <standard>
        <framework>Playwright</framework>
        <type>E2E</type>
        <source>docs/architecture.md#Comprehensive-Testing-Strategy</source>
      </standard>
    </standards>
    <locations>
      <location>tests/</location>
      <note>Mirroring the application's module structure (e.g., `tests/unit/`, `tests/integration/`).</note>
    </locations>
    <ideas>
      <idea ac="1">
        <description>Write unit tests for puzzle dependency logic in `services/ai_service.py`, mocking the Gemini API to verify correct prompt construction.</description>
      </idea>
      <idea ac="2">
        <description>Write unit tests for the puzzle solvability verification functions in `services/game_logic.py`.</description>
      </idea>
      <idea ac="2">
        <description>Integration tests for API endpoints that trigger puzzle generation, ensuring that only solvable sequences are created.</description>
      </idea>
    </ideas>
  </tests>
</story-context>