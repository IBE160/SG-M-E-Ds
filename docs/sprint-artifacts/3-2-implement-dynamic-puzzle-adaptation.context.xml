<story-context id=".bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>3</epicId>
    <storyId>2</storyId>
    <title>Implement Dynamic Puzzle Adaptation</title>
    <status>drafted</status>
    <generatedAt>2025-12-04</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/sprint-artifacts/3-2-implement-dynamic-puzzle-adaptation.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>game designer</asA>
    <iWant>the AI to dynamically adapt puzzles based on player actions and game state</iWant>
    <soThat>the challenges feel responsive and personalized</soThat>
    <tasks>
- [ ] AC 1: Extend `services/ai_service.py` for puzzle adaptation.
  - [ ] Subtask: Implement a function to evaluate player attempts against puzzle solutions.
  - [ ] Subtask: Formulate prompts for the Gemini API to request adaptations (e.g., hints, difficulty adjustments) based on player performance and `GameSession.puzzle_state`.
  - [ ] Subtask: Implement logic to parse AI-generated adaptations.
- [ ] AC 1: Create or update Flask API route for player puzzle interaction/adaptation.
  - [ ] Subtask: Define a `POST /evaluate_puzzle_solution` endpoint in `routes.py`.
  - [ ] Subtask: This endpoint will receive player attempts, call `services/ai_service.py` for evaluation and adaptation, and return feedback/adapted puzzle details.
- [ ] AC 2: Integrate puzzle adaptation with game state.
  - [ ] Subtask: Update `GameSession.puzzle_state` to reflect puzzle progression, AI adaptations, or hints provided.
- [ ] AC 1, 2: Implement unit and integration tests.
  - [ ] Subtask: Write unit tests for `services/ai_service.py` functions, mocking the Gemini API to verify evaluation and adaptation logic.
  - [ ] Subtask: Write integration tests for `POST /evaluate_puzzle_solution` Flask route, verifying API interaction and `GameSession.puzzle_state` updates.
  - [ ] Subtask: Manual/Exploratory testing to assess the responsiveness and personalization of AI puzzle adaptations.
</tasks>
  </story>

  <acceptanceCriteria>
    <criterion>Given a puzzle has been generated, when the player attempts a solution, then the AI evaluates the attempt and adapts the puzzle's difficulty or provides contextual hints if needed.</criterion>
    <criterion>And the game state reflects the puzzle's progression.</criterion>
</acceptanceCriteria>

  <artifacts>
<docs>
    <doc>
        <path>docs/prd.md</path>
        <title>Product Requirements Document: AI Escape</title>
        <section>FR-005: Detailed specifications for puzzle types</section>
        <snippet>Detailed specifications for puzzle types (Observation, Riddle, etc.) and the AI's adaptation logic will be developed.</snippet>
    </doc>
    <doc>
        <path>docs/architecture.md</path>
        <title>Architecture</title>
        <section>AI Service Integration</section>
        <snippet>Utilizes Gemini Pro / Gemini 1.5 Pro.</snippet>
    </doc>
    <doc>
        <path>docs/architecture.md</path>
        <title>Architecture</title>
        <section>AI Client Library</section>
        <snippet>Employs `google-generativeai 0.8.5` for interacting with the Gemini API.</snippet>
    </doc>
    <doc>
        <path>docs/architecture.md</path>
        <title>Architecture</title>
        <section>Prompt Management Strategy</section>
        <snippet>Structured Prompting with "Puzzle Dependency Chains".</snippet>
    </doc>
    <doc>
        <path>docs/architecture.md</path>
        <title>Architecture</title>
        <section>Data Architecture</section>
        <snippet>`GameSession.puzzleState` will be crucial for providing context to the AI for dynamic adaptation.</snippet>
    </doc>
    <doc>
        <path>docs/epics.md</path>
        <title>ibe160 - Epic Breakdown</title>
        <section>Epic 3: The AI Puzzle Master</section>
        <snippet>This Epic focuses on empowering the AI to dynamically generate and adapt puzzles within the "AI Escape" game, building upon the coherent narrative framework established in Epic 2.</snippet>
    </doc>
    <doc>
        <path>docs/epics.md</path>
        <title>ibe160 - Epic Breakdown</title>
        <section>Story 3.2: Implement Dynamic Puzzle Adaptation</section>
        <snippet>Story 3.2 focuses on enabling the AI to dynamically adapt puzzles based on player actions and game state, providing responsive and personalized challenges.</snippet>
    </doc>
    <doc>
        <path>docs/ux-design-specification.md</path>
        <title>AI Escape - UX Design Specification</title>
        <section>5. User Journey Flows</section>
        <snippet>UX Design outlines user journey flows for New Game Creation and Load Game, which will rely on the backend's game state management to function correctly. This implies the need for dynamic content in the UI.</snippet>
    </doc>
</docs>
    <code>
        <code-ref>
            <path>services/ai_service.py</path>
            <kind>file</kind>
            <reason>Extend for puzzle adaptation logic (evaluate player attempts, formulate prompts for adaptations)</reason>
        </code-ref>
        <code-ref>
            <path>routes.py</path>
            <kind>file</kind>
            <reason>Create or update Flask API route (`POST /evaluate_puzzle_solution`) for player puzzle interaction/adaptation</reason>
        </code-ref>
        <code-ref>
            <path>models.py</path>
            <kind>file</kind>
            <reason>Update `GameSession.puzzle_state` to reflect puzzle progression, AI adaptations, or hints provided</reason>
        </code-ref>
        <code-ref>
            <path>tests/</path>
            <kind>directory</kind>
            <reason>For new unit and integration tests</reason>
        </code-ref>
    </code>
    <dependencies>
      <python>
        <package name="Flask" version="3.1.2" />
        <package name="python-dotenv" version="?" />
        <package name="gunicorn" version="?" />
        <package name="pytest" version="?" />
        <package name="google-generativeai" version="0.8.5" />
        <note>Core Python dependencies for the Flask application and Google Gemini API client.</note>
      </python>
      <node>
        <package name="playwright" version="?" />
        <note>Existing Node.js project dependencies for E2E testing.</note>
      </node>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint>
        <type>Required Pattern</type>
        <description>Python Flask application structure (modular, with `app.py`, `static/`, `templates/`, `models.py`, `routes.py`, `services/`, `tests/`).</description>
        <source>docs/architecture.md#Project-Structure</source>
    </constraint>
    <constraint>
        <type>Required Pattern</type>
        <description>WCAG 2.1 Level AA accessibility compliance.</description>
        <source>docs/architecture.md#Accessibility-Implementation</source>
    </constraint>
    <constraint>
        <type>Required Pattern</type>
        <description>Stateless JWT Authentication.</description>
        <source>docs/architecture.md#Security-Architecture</source>
    </constraint>
    <constraint>
        <type>Layer Restriction</type>
        <description>Frontend (Jinja2 templates/Static assets) &lt;-> Backend (Flask Routes/API Endpoints).</description>
        <source>docs/architecture.md#Integration-Points</source>
    </constraint>
    <constraint>
        <type>Layer Restriction</type>
        <description>Flask Routes/API Endpoints &lt;-> AI Service (Gemini API).</description>
        <source>docs/architecture.md#Integration-Points</source>
    </constraint>
    <constraint>
        <type>Layer Restriction</type>
        <description>Flask Routes/API Endpoints &lt;-> Database (Supabase PostgreSQL via SQLAlchemy).</description>
        <source>docs/architecture.md#Integration-Points</source>
    </constraint>
    <constraint>
        <type>Testing Requirement</type>
        <description>Unit Tests (Pytest with `pytest-mock`).</description>
        <source>docs/architecture.md#Comprehensive-Testing-Strategy</source>
    </constraint>
    <constraint>
        <type>Testing Requirement</type>
        <description>Integration Tests (Pytest).</description>
        <source>docs/architecture.md#Comprehensive-Testing-Strategy</source>
    </constraint>
    <constraint>
        <type>Testing Requirement</type>
        <description>E2E Tests (Playwright).</description>
        <source>docs/architecture.md#Comprehensive-Testing-Strategy</source>
    </constraint>
    <constraint>
        <type>Coding Standard</type>
        <description>Python Classes: `PascalCase`, Python Functions/Variables: `snake_case`, Python Modules/Files: `snake_case`, Database Tables: `snake_case` (plural), Database Columns: `snake_case`, API Endpoints: `kebab-case` for URL paths, `snake_case` for query parameters, Constants: `SCREAMING_SNAKE_CASE`.</description>
        <source>docs/architecture.md#Consistency-Rules</source>
    </constraint>
    <constraint>
        <type>Coding Standard</type>
        <description>Code Organization: Modular Flask application layout.</description>
        <source>docs/architecture.md#Code-Organization</source>
    </constraint>
</constraints>

<interfaces>
    <interface>
        <name>/evaluate_puzzle_solution</name>
        <kind>REST endpoint</kind>
        <signature>POST /evaluate_puzzle_solution</signature>
        <path>routes.py</path>
    </interface>
    <interface>
        <name>/adapt_puzzle</name>
        <kind>REST endpoint</kind>
        <signature>POST /adapt_puzzle</signature>
        <path>routes.py</path>
    </interface>
</interfaces>
  <tests>
    <standards>
      <standard>
        <framework>Pytest</framework>
        <type>Unit, Integration</type>
        <note>Unit tests should mock the Gemini API.</note>
        <source>docs/architecture.md#Testing-Strategy</source>
      </standard>
      <standard>
        <framework>Playwright</framework>
        <type>E2E</type>
        <source>docs/architecture.md#Comprehensive-Testing-Strategy</source>
      </standard>
    </standards>
    <locations>
      <location>tests/</location>
      <note>Mirroring the application's module structure (e.g., `tests/unit/`, `tests/integration/`).</note>
    </locations>
    <ideas>
      <idea ac="1">
        <description>Write unit tests for `services/ai_service.py` functions, mocking the Gemini API to verify evaluation and adaptation logic.</description>
      </idea>
      <idea ac="2">
        <description>Write integration tests for `POST /evaluate_puzzle_solution` Flask route, verifying API interaction and `GameSession.puzzle_state` updates.</description>
      </idea>
      <idea ac="2">
        <description>Manual/Exploratory testing to assess the responsiveness and personalization of AI puzzle adaptations.</description>
      </idea>
    </ideas>
  </tests>
</story-context>